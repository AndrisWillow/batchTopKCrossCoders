{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from dictionary_learning import CrossCoder\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch as th\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "th.set_grad_enabled(False)\n",
    "exp_name = \"eval_crosscoder\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosscoder_path = \"/dlabscratch1/jminder/repositories/representation-structure-comparison/checkpoints/l13-mu4.1e-02-lr1e-04/ae_final.pt\"\n",
    "extra_args = []\n",
    "exp_id = \"\"\n",
    "device = \"cuda\"\n",
    "seed = 42\n",
    "base_model = \"google/gemma-2-2b\"\n",
    "instruct_model = \"google/gemma-2-2b-it\"\n",
    "layer = 13\n",
    "activation_dir = Path(\n",
    "    \"/dlabscratch1/jminder/repositories/representation-structure-comparison/activations\"\n",
    ")\n",
    "validation_size = 10**6\n",
    "model_batch_size = 64\n",
    "workers = 12\n",
    "SEQ_LEN = 1024\n",
    "n = 100\n",
    "crosscoder_batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected features: 4532\n",
      "First 10 selected indices: [55, 60, 78, 82, 95, 112, 119, 130, 140, 221]\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\n",
    "    \"/dlabscratch1/cdumas/representation-structure-comparison/notebooks/results/eval_crosscoder/l13-mu4.1e-02-lr1e-04_ae_final/data\"\n",
    ")\n",
    "df = pd.read_csv(data_path / \"feature_df.csv\")\n",
    "# Filter for IT only and Base only features that are not dead\n",
    "selected_features = df[(df['tag'].isin(['IT only', 'Base only'])) & (df['dead'] == False)]\n",
    "\n",
    "# Get the indices of the selected features in the dataframe\n",
    "selected_indices = selected_features.index.tolist()\n",
    "\n",
    "print(f\"Number of selected features: {len(selected_indices)}\")\n",
    "print(f\"First 10 selected indices: {selected_indices[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(\"/dlabscratch1/cdumas/representation-structure-comparison/results-runai/max_activating_examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the max activating examples\n",
    "# max_activating_ex_mini = th.load(save_path / \"max_activating_examples_mini_final_cleaned.pt\")\n",
    "# max_activating_examples_base = th.load(save_path / \"max_activating_examples_base.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_241427/2677649820.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  max_activating_examples_chat = th.load(save_path / \"chat/chat_final.pt\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_activating_examples_chat = th.load(save_path / \"chat/chat_final.pt\")\n",
    "type(max_activating_examples_chat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c1dcc53a0741cbbcbf46ad7af08907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Combobox(value='', continuous_update=False, description='Feature:', options=('55', '60', '78', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from feature_dashboard import FeatureCentricDashboard\n",
    "from transformers import AutoTokenizer\n",
    "dashboard = FeatureCentricDashboard(max_activation_examples=max_activating_examples_chat, tokenizer=AutoTokenizer.from_pretrained(instruct_model))\n",
    "dashboard.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE LENS (PAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import SAE, SAEConfig\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--base-device\", type=str, default=device)\n",
    "parser.add_argument(\"--instruct-device\", type=str, default=device)\n",
    "args = parser.parse_args(extra_args)\n",
    "\n",
    "base_config_dict = {\n",
    "    \"architecture\": \"standard\",\n",
    "    \"d_in\": activation_dim,\n",
    "    \"d_sae\": dict_size,\n",
    "    \"dtype\": \"float32\",\n",
    "    \"model_name\": base_model,\n",
    "    \"hook_name\": f\"blocks.{layer}.hook_resid_post\",\n",
    "    \"hook_layer\": layer,\n",
    "    \"hook_head_index\": None,\n",
    "    \"activation_fn_str\": \"relu\",\n",
    "    \"finetuning_scaling_factor\": False,\n",
    "    \"sae_lens_training_version\": None,\n",
    "    \"prepend_bos\": True,\n",
    "    \"dataset_path\": None,\n",
    "    \"context_size\": 1024,\n",
    "    \"dataset_trust_remote_code\": False,\n",
    "    \"apply_b_dec_to_input\": False,\n",
    "    \"normalize_activations\": None,\n",
    "    \"device\": \"cpu\",\n",
    "    # \"device\": args.base_device,\n",
    "}\n",
    "base_config = SAEConfig.from_dict(base_config_dict)\n",
    "\n",
    "it_config_dict = base_config_dict.copy()\n",
    "it_config_dict[\"model_name\"] = instruct_model\n",
    "it_config_dict[\"device\"] = args.instruct_device\n",
    "it_config = SAEConfig.from_dict(it_config_dict)\n",
    "\n",
    "\n",
    "def gen_state_dict(model_idx):\n",
    "    return {\n",
    "        \"b_enc\": crosscoder.encoder.bias,\n",
    "        \"W_enc\": crosscoder.encoder.weight[model_idx],\n",
    "        \"b_dec\": crosscoder.decoder.bias[model_idx],\n",
    "        \"W_dec\": crosscoder.decoder.weight[model_idx],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sae = SAE(base_config)\n",
    "base_sae.load_state_dict(gen_state_dict(0))\n",
    "base_sae.fold_W_dec_norm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951a276dd9984ffa82c7aa04085b8ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer, utils\n",
    "from sae_dashboard.sae_vis_data import SaeVisConfig\n",
    "from sae_dashboard.sae_vis_runner import SaeVisRunner\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "# Load model and SAE\n",
    "model = HookedTransformer.from_pretrained_no_processing(\n",
    "    base_model, device=args.base_device, dtype=\"float16\", n_devices=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4d3a567d5c4e91aafca28ded85e2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388b9084a6144e9f8d7a6a6ff52bdcc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008f2e611e6d4179b2766489c9d9ce10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f013570aeb0340dda87b5929f2442778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fineweb = load_dataset(\n",
    "    \"HuggingFaceFW/fineweb\",\n",
    "    name=\"sample-10BT\",\n",
    "    split=\"train\",\n",
    "    cache_dir=Path(\"/dlabscratch1/cdumas/.cache/huggingface/datasets/\"),\n",
    ")\n",
    "\n",
    "# select 300 random samples\n",
    "indices = th.randperm(len(fineweb))[:300]\n",
    "fineweb = fineweb.select(indices)\n",
    "fineweb_tokenized_data = utils.tokenize_and_concatenate(fineweb, model.tokenizer, max_length=SEQ_LEN)  # type: ignore\n",
    "lmsys = load_from_disk(\"/dlabscratch1/public/datasets/lmsys-chat-1m-formatted/\")\n",
    "indices = th.randperm(len(lmsys))[:300]\n",
    "lmsys = lmsys.select(indices)\n",
    "lmsys_tokenized_data = utils.tokenize_and_concatenate(lmsys, model.tokenizer, max_length=SEQ_LEN)  # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the two datasets\n",
    "from datasets import concatenate_datasets\n",
    "tokenized_data = concatenate_datasets([fineweb_tokenized_data, lmsys_tokenized_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = th.load(\"/dlabscratch1/cdumas/representation-structure-comparison/results/eval_crosscoder/checkpoints_l13-mu4.0e-02-lr1e-04_ae_90000.pt/data/only_base_decoder_feature_indices.pt\", weights_only=True).tolist()\n",
    "it_features = th.load(\"/dlabscratch1/cdumas/representation-structure-comparison/results/eval_crosscoder/checkpoints_l13-mu4.0e-02-lr1e-04_ae_90000.pt/data/only_it_decoder_feature_indices.pt\", weights_only=True).tolist()\n",
    "shared_features = th.load(\"/dlabscratch1/cdumas/representation-structure-comparison/results/eval_crosscoder/checkpoints_l13-mu4.0e-02-lr1e-04_ae_90000.pt/data/shared_decoder_feature_indices.pt\", weights_only=True).tolist()\n",
    "all_features = base_features[:10] + it_features[:10] + shared_features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78, 95, 222, 263, 377, 418, 585, 593, 603, 652]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_dashboard.sae_vis_data import SaeVisData\n",
    "\n",
    "\n",
    "# Configure visualization\n",
    "config = SaeVisConfig(\n",
    "    hook_point=base_sae.cfg.hook_name,\n",
    "    features=all_features,\n",
    "    device=args.base_device,\n",
    "    dtype=\"bfloat16\",\n",
    "    minibatch_size_features=64,\n",
    "    minibatch_size_tokens=16,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbec8f3bd1f404e9d49a637b1fa2b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=0, description='Feature:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ddeb4d9846546e4818abfdbdbe72f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def check_feature_type(feature):\n",
    "    if feature in base_features:\n",
    "        return \"Base\"\n",
    "    elif feature in it_features:\n",
    "        return \"IT\"\n",
    "    elif feature in shared_features:\n",
    "        return \"Shared\"\n",
    "    else:\n",
    "        return \"Not found in any list\"\n",
    "\n",
    "feature_input = widgets.IntText(\n",
    "    value=0,\n",
    "    description='Feature:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_value_change(change):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        feature_type = check_feature_type(change['new'])\n",
    "        print(f\"Feature {change['new']} is: {feature_type}\")\n",
    "\n",
    "feature_input.observe(on_value_change, names='value')\n",
    "\n",
    "display(feature_input, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a21be892d04fef8349c6848784e8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forward passes to cache data for vis:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d19788cd9bb45e690a0bc9d87267c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting vis data from cached data:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9aad1b7a602485b81bd031dcd42c2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Feature batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Task </span>┃<span style=\"font-weight: bold\"> Time </span>┃<span style=\"font-weight: bold\"> Pct % </span>┃\n",
       "┡━━━━━━╇━━━━━━╇━━━━━━━┩\n",
       "└──────┴──────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━┳━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTask\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTime\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPct %\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━╇━━━━━━╇━━━━━━━┩\n",
       "└──────┴──────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ea541d3a694d73877f9b98b6e4fbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = SaeVisRunner(config).run(encoder=base_sae, model=model, tokens=tokenized_data['tokens'][:16])\n",
    "\n",
    "# Save feature-centric visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd626ee24584f1cb81dac5782d5fd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sae_dashboard.data_writing_fns import save_feature_centric_vis\n",
    "save_feature_centric_vis(sae_vis_data=data, filename=\"feature_dashboard_base.html\", separate_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IT visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it_sae = SAE(it_config)\n",
    "# it_sae.load_state_dict(gen_state_dict(1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

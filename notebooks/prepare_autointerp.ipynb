{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch as th\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from tqdm.auto import tqdm, trange\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.utils import load_latent_df, push_latent_df, apply_masks\n",
    "from tools.cc_utils import chat_only_latent_indices, base_only_latent_indices, shared_latent_indices\n",
    "from tools.latent_scaler.plot import plot_scaler_histograms\n",
    "from tools.latent_scaler.utils import load_betas, get_beta_from_index\n",
    "from tools.paths import *\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tools.utils import load_activation_dataset, load_crosscoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_store_dir = Path(\"/workspace/data/activations\")\n",
    "base_model_id = \"google/gemma-2-2b\"\n",
    "chat_model_id = \"google/gemma-2-2b-it\"\n",
    "layer = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d338c51f7c466d8271381be34660b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c813949abb944576b5ccc3e62ad7a88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_id, attn_implementation=\"eager\")\n",
    "chat_model = AutoModelForCausalLM.from_pretrained(chat_model_id, attn_implementation=\"eager\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_latent_df()\n",
    "cc = load_crosscoder().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 73728, 2304])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.decoder.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 73728])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.decoder.weight.norm(dim=2).sum(dim=0, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 73728])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " == cc.decoder.weight.norm(dim=2).sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack the decoder weights from both layers along the last dimension\n",
    "# Original shape: [2, 73728, 2304]\n",
    "stacked_weights = th.cat([cc.decoder.weight[0], cc.decoder.weight[1]], dim=1)\n",
    "\n",
    "th.allclose(stacked_weights.norm(dim=-1), cc.decoder.weight.norm(dim=(0,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fineweb cache from /workspace/data/activations/gemma-2-2b/fineweb-1m-sample/validation/layer_13_out and /workspace/data/activations/gemma-2-2b-it/fineweb-1m-sample/validation/layer_13_out\n",
      "Loading lmsys cache from /workspace/data/activations/gemma-2-2b/lmsys-chat-1m-gemma-formatted/validation/layer_13_out and /workspace/data/activations/gemma-2-2b-it/lmsys-chat-1m-gemma-formatted/validation/layer_13_out\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5204776, 5104976)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fineweb_cache, lmsys_cache = load_activation_dataset(\n",
    "    activation_store_dir,\n",
    "    base_model=base_model_id.split(\"/\")[-1],\n",
    "    instruct_model=chat_model_id.split(\"/\")[-1],\n",
    "    layer=layer,\n",
    "    split=\"validation\",\n",
    ")\n",
    "tokens_fineweb = fineweb_cache.tokens[0]\n",
    "tokens_lmsys = lmsys_cache.tokens[0]\n",
    "len(tokens_fineweb), len(tokens_lmsys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sequences(tokenizer, tokens):\n",
    "    # Find indices of BOS tokens\n",
    "    indices_of_bos = th.where(tokens == tokenizer.bos_token_id)[0]\n",
    "\n",
    "    # Split tokens into sequences starting with BOS token\n",
    "    sequences = []\n",
    "    index_to_seq_pos = []  # List of (sequence_idx, idx_in_sequence) tuples\n",
    "    ranges = []\n",
    "    for i in trange(len(indices_of_bos)):\n",
    "        start_idx = indices_of_bos[i]\n",
    "        end_idx = indices_of_bos[i+1] if i < len(indices_of_bos)-1 else len(tokens)\n",
    "        sequence = tokens[start_idx:end_idx]\n",
    "        sequences.append(sequence)\n",
    "        ranges.append((start_idx, end_idx))\n",
    "        # Add mapping for each token in this sequence\n",
    "        for j in range(len(sequence)):\n",
    "            orig_idx = start_idx + j\n",
    "            index_to_seq_pos.append((i, j))\n",
    "\n",
    "    return sequences, index_to_seq_pos, ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e40035b14848bb993d225e5a8dd430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_lmsys, idx_to_seq_pos_lmsys, ranges_lmsys = split_into_sequences(tokenizer, tokens_lmsys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f81934c172e4381a1d964537ccd44b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_fineweb, idx_to_seq_pos_fineweb, ranges_fineweb = split_into_sequences(tokenizer, tokens_fineweb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7789])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_only_ids = chat_only_latent_indices()\n",
    "sampled_shared_ids = th.load(\"/workspace/data/sampled_shared_indices.pt\", weights_only=True)\n",
    "base_only_ids = base_only_latent_indices()\n",
    "\n",
    "latent_ids = th.cat([chat_only_ids, sampled_shared_ids, base_only_ids])\n",
    "latent_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' argument of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'max_batch_size' argument instead.\n",
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hidden state layers: 27\n",
      "Hidden state shape for one layer: torch.Size([1, 65, 2304])\n",
      "\n",
      "Sample values from middle layer 13:\n",
      "tensor([ 0.6860,  1.0977,  3.0149,  0.0941, -0.1594], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Get sequence 100 from lmsys dataset\n",
    "random_index = 0\n",
    "seq_idx = idx_to_seq_pos_lmsys[random_index][0]\n",
    "seq_pos = idx_to_seq_pos_lmsys[random_index][1]\n",
    "sequence = seq_lmsys[seq_idx]\n",
    "chat_model.eval()\n",
    "chat_model.cuda()\n",
    "# Run forward pass through model to get hidden states\n",
    "with th.no_grad():\n",
    "    outputs = chat_model(sequence.unsqueeze(0).cuda(), output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states\n",
    "\n",
    "print(f\"Number of hidden state layers: {len(hidden_states)}\")\n",
    "print(f\"Hidden state shape for one layer: {hidden_states[0].shape}\")\n",
    "# Print first few values of middle layer as example\n",
    "middle_layer = len(hidden_states)//2\n",
    "print(f\"\\nSample values from middle layer {middle_layer}:\")\n",
    "print(hidden_states[middle_layer+1][0,seq_pos,:5 ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6852,  1.0975,  3.0141,  ..., -1.5590,  0.3698, -1.1332])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmsys_cache[0][:5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@th.no_grad()\n",
    "def get_positive_activations(sequences, ranges, dataset, cc, latent_ids):\n",
    "    \"\"\"\n",
    "    Extract positive activations and their indices from sequences.\n",
    "    \n",
    "    Args:\n",
    "        sequences: List of sequences\n",
    "        ranges: List of (start_idx, end_idx) tuples for each sequence\n",
    "        dataset: Dataset containing activations\n",
    "        cc: Object with get_activations method\n",
    "        latent_ids: Tensor of latent indices to extract\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (activations tensor, indices tensor) where indices are in \n",
    "        (seq_idx, seq_pos, feature_pos) format\n",
    "    \"\"\"\n",
    "    out_activations = []\n",
    "    out_ids = []\n",
    "    for seq_idx in trange(len(sequences)):\n",
    "        activations = th.stack([dataset[j].cuda() for j in range(ranges[seq_idx][0], ranges[seq_idx][1])])\n",
    "        feature_activations = cc.get_activations(activations, latent_ids)\n",
    "        assert feature_activations.shape == (len(activations), len(latent_ids))\n",
    "        # Get indices where feature activations are positive\n",
    "        pos_mask = feature_activations > 0\n",
    "        pos_indices = th.nonzero(pos_mask, as_tuple=True)\n",
    "\n",
    "        # Get the positive activation values\n",
    "        pos_activations = feature_activations[pos_mask]\n",
    "        \n",
    "        # Create sequence indices tensor matching size of positive indices\n",
    "        seq_idx_tensor = th.full_like(pos_indices[0], seq_idx)\n",
    "        \n",
    "        # Stack indices into (seq_idx, seq_pos, feature_pos) format\n",
    "        pos_ids = th.stack([seq_idx_tensor, pos_indices[0], pos_indices[1]], dim=1)\n",
    "        \n",
    "        out_activations.append(pos_activations)\n",
    "        out_ids.append(pos_ids)\n",
    "        \n",
    "    out_activations = th.cat(out_activations)\n",
    "    out_ids = th.cat(out_ids)\n",
    "    return out_activations, out_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2867eb0ec17944fc92d717eba84f5f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_acts_fineweb, out_ids_fineweb = get_positive_activations(seq_fineweb, ranges_fineweb, fineweb_cache, cc, latent_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b203699718144b65913b175e2c23be4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_acts_lmsys, out_ids_lmsys = get_positive_activations(seq_lmsys, ranges_lmsys, lmsys_cache, cc, latent_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([332404028]) torch.Size([332404028, 3])\n"
     ]
    }
   ],
   "source": [
    "out_acts = th.cat([out_acts_fineweb, out_acts_lmsys])\n",
    "# add offset to seq_idx in out_ids_lmsys\n",
    "out_ids_lmsys[:, 0] += len(seq_fineweb)\n",
    "out_ids = th.cat([out_ids_fineweb, out_ids_lmsys])\n",
    "print(out_acts.shape, out_ids.shape)\n",
    "th.save(out_acts, \"out_acts.pt\")\n",
    "th.save(out_ids, \"out_ids.pt\")\n",
    "th.save(latent_ids, \"latent_ids.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_all = seq_fineweb + seq_lmsys\n",
    "# Find max length\n",
    "max_len = max(len(s) for s in sequences_all)\n",
    "\n",
    "# Pad each sequence to max length\n",
    "padded_seqs = [th.cat([s, th.full((max_len - len(s),), tokenizer.pad_token_id, device=s.device)]) for s in sequences_all]\n",
    "\n",
    "# Convert to tensor and save\n",
    "padded_tensor = th.stack(padded_seqs)\n",
    "th.save(padded_tensor, \"padded_sequences.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23424, 1024])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38d3ca5e4af4116aedd2432d602e2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "out_acts.pt:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b408cd74ec4185adcef0a7e3bd7015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "out_ids.pt:   0%|          | 0.00/7.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7c2ed435ec495d9dbc87fc565b8ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "latent_ids.pt:   0%|          | 0.00/63.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files uploaded to Hugging Face Hub\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Initialize Hugging Face API\n",
    "api = HfApi()\n",
    "\n",
    "repo_id = \"science-of-finetuning/autointerp-data-gemma-2-2b-l13-mu4.1e-02-lr1e-04\"\n",
    "# Push all tensors to HF Hub\n",
    "# api.create_repo(repo_id=repo_id, repo_type=\"dataset\")\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"out_acts.pt\",\n",
    "    path_in_repo=\"activations.pt\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"out_ids.pt\",\n",
    "    path_in_repo=\"indices.pt\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"padded_sequences.pt\",\n",
    "    path_in_repo=\"sequences.pt\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"latent_ids.pt\",\n",
    "    path_in_repo=\"latent_ids.pt\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "print(\"All files uploaded to Hugging Face Hub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   55,    60,    82,  ..., 73636, 73683, 73708])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97364568c91c4b7f8369380db2173312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "indices.pt:  33%|###3      | 2.66G/7.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f765654af9d6487fb162e8443581105b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "latent_ids.pt:   0%|          | 0.00/63.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_autointerp_data(repo_id=\"science-of-finetuning/autointerp-data-gemma-2-2b-l13-mu4.1e-02-lr1e-04\"):\n",
    "    \"\"\"\n",
    "    Load the autointerp data from Hugging Face Hub.\n",
    "    \n",
    "    Args:\n",
    "        repo_id (str): The Hugging Face Hub repository ID containing the data\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (activations, indices, sequences) tensors where:\n",
    "            - activations: tensor of shape [n_total_activations] containing latent activations\n",
    "            - indices: tensor of shape [n_total_activations, 3] containing (seq_idx, seq_pos, latent_idx)\n",
    "            - sequences: tensor of shape [n_total_sequences, max_seq_len] containing the padded input sequences (right padded)\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    from huggingface_hub import hf_hub_download\n",
    "    \n",
    "    # Download files from hub\n",
    "    activations_path = hf_hub_download(repo_id=repo_id, filename=\"activations.pt\", repo_type=\"dataset\")\n",
    "    indices_path = hf_hub_download(repo_id=repo_id, filename=\"indices.pt\", repo_type=\"dataset\") \n",
    "    sequences_path = hf_hub_download(repo_id=repo_id, filename=\"sequences.pt\", repo_type=\"dataset\")\n",
    "    latent_ids_path = hf_hub_download(repo_id=repo_id, filename=\"latent_ids.pt\", repo_type=\"dataset\")\n",
    "\n",
    "    # Load tensors\n",
    "    activations = torch.load(activations_path, weights_only=False)\n",
    "    indices = torch.load(indices_path, weights_only=False)\n",
    "    sequences = torch.load(sequences_path, weights_only=False)\n",
    "    latent_ids = torch.load(latent_ids_path, weights_only=False)\n",
    "    \n",
    "    return activations, indices, sequences, latent_ids\n",
    "\n",
    "# Test loading the data\n",
    "activations, indices, sequences, latent_ids = load_autointerp_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(55)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_dashboard.visualization_utils import activation_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = th.zeros_like(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5654, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[indices[:, 0] == 0 & indices[:, 2] == 0]\n",
    "acts[indices[:, 0] == 0 & indices[:, 1] == 0] = activations\n",
    "acts[indices[:, 0] == 0 & indices[:, 1] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations[(indices[:, 2] != 0)] = 0\n",
    "topk = th.topk(activations, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([15682,   415,     0], device='cuda:0'),\n",
       " tensor(28.2579, device='cuda:0'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[topk.indices[0]], activations[topk.indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focus_indices = th.tensor([\n",
    "    57717,\n",
    "    68066,\n",
    "    72073,\n",
    "    51408,\n",
    "    51823,\n",
    "    65708,\n",
    "    72364,\n",
    "    9751,\n",
    "    221,\n",
    "    31726\n",
    "])\n",
    "meanings = [\n",
    "    \"Knowledge Boundaries\",\n",
    "    \"Identity\",\n",
    "    \"User Request Reinterpretation\",\n",
    "    \"Complex Ethical Questions\",\n",
    "    \"Broad Inquiries\",\n",
    "    \"Describing stuff as important / the importance of stuff\",\n",
    "    \"List\",\n",
    "    \"Programming Function Names, End of Programming Questions\",\n",
    "    \"Today Date\",\n",
    "    \"User wants free tools\"\n",
    "]\n",
    "len(meanings), len(focus_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,    67],\n",
       "        [    0,     0,   227],\n",
       "        [    0,     0,   343],\n",
       "        ...,\n",
       "        [23423,   450,  7477],\n",
       "        [23423,   450,  7702],\n",
       "        [23423,   450,  7752]], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2456, 2909, 3101, 2213, 2235, 2807, 3117,  387,    7, 1362])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor to store results\n",
    "focus_indices_lookup = th.zeros(len(focus_indices), dtype=th.long)\n",
    "\n",
    "# For each focus index, find its position in the indices tensor\n",
    "for i, idx in enumerate(focus_indices):\n",
    "    # Find where this index appears in indices[:,0]\n",
    "    matches = (latent_ids == idx).nonzero()\n",
    "    if len(matches) > 0:\n",
    "        focus_indices_lookup[i] = matches[0]\n",
    "\n",
    "focus_indices_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2456, 2909, 3101, 2213, 2235, 2807, 3117, 387, 7, 1362]\n"
     ]
    }
   ],
   "source": [
    "print(focus_indices_lookup.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Knowledge Boundaries', 'Identity', 'User Request Reinterpretation', 'Complex Ethical Questions', 'Broad Inquiries', 'Describing stuff as important / the importance of stuff', 'List', 'Programming Function Names, End of Programming Questions', 'Today Date', 'User wants free tools']\n"
     ]
    }
   ],
   "source": [
    "print(meanings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a925ade90f147da80e536ace3e84ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "latent_ids.pt:   0%|          | 0.00/63.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tools.utils import load_latent_df\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "    \n",
    "# Download files from hub\n",
    "latent_ids_path = hf_hub_download(repo_id=\"science-of-finetuning/autointerp-data-gemma-2-2b-l13-mu4.1e-02-lr1e-04\", filename=\"latent_ids.pt\", repo_type=\"dataset\")\n",
    "\n",
    "# Load tensors\n",
    "latent_ids = torch.load(latent_ids_path, weights_only=False)\n",
    "    \n",
    "df = load_latent_df(), latent_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
